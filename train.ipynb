{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:43.065Z",
     "start_time": "2024-09-09T08:12:43.010286Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc file Excel\n",
    "df = pd.read_excel('Chatbot_Custom.xlsx', engine='openpyxl')\n",
    "\n",
    "# Hiển thị dữ liệu\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         title                                Question  Answer_label  \\\n",
      "0  1719/QĐ-TTg             Mục tiêu của dự án 2 là gì?             0   \n",
      "1  1719/QĐ-TTg              Dự án 2 có mục tiêu là gì?             0   \n",
      "2  1719/QĐ-TTg                   Mục tiêu của dự án 2?             0   \n",
      "3  1719/QĐ-TTg  Đối tượng thụ hưởng của dự án 2 là ai?             1   \n",
      "4  1719/QĐ-TTg        Đối tượng thụ hưởng của dự án 2?             1   \n",
      "\n",
      "                                              Answer  \n",
      "0  Mục tiêu của Dự án 2 thuộc Chương trình mục ti...  \n",
      "1  Mục tiêu của Dự án 2 thuộc Chương trình mục ti...  \n",
      "2  Mục tiêu của Dự án 2 thuộc Chương trình mục ti...  \n",
      "3  Đối tượng thụ hưởng của Dự án 2 thuộc Chương t...  \n",
      "4  Đối tượng thụ hưởng của Dự án 2 thuộc Chương t...  \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:43.109021Z",
     "start_time": "2024-09-09T08:12:43.069009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Đảm bảo cột 'label' là số nguyên\n",
    "df['Answer_label'] = df['Answer_label'].astype(int)\n",
    "\n",
    "# Chọn một hàng ngẫu nhiên từ mỗi nhóm\n",
    "eval_df = df.groupby('Answer_label').apply(lambda x: x.sample(n=1)).reset_index(drop=True)\n",
    "\n",
    "# Hiển thị DataFrame mới\n",
    "print(eval_df.head())\n"
   ],
   "id": "4933c2fb660a2034",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         title                          Question  Answer_label  \\\n",
      "0  1719/QĐ-TTg       Mục tiêu của dự án 2 là gì?             0   \n",
      "1  1719/QĐ-TTg  Đối tượng thụ hưởng của dự án 2?             1   \n",
      "2  1719/QĐ-TTg        Dự án 2 có nội dung là gì?             2   \n",
      "3  1719/QĐ-TTg           Nội dung chính dự án 2?             3   \n",
      "4  1719/QĐ-TTg    Số nội dung chính của dự án 2?             4   \n",
      "\n",
      "                                              Answer  \n",
      "0  Mục tiêu của Dự án 2 thuộc Chương trình mục ti...  \n",
      "1  Đối tượng thụ hưởng của Dự án 2 thuộc Chương t...  \n",
      "2  Nội dung của Dự án 2 thuộc Chương trình mục ti...  \n",
      "3  Nội dung chính của Dự án 2 thuộc Chương trình ...  \n",
      "4  Dự án 2 thuộc Chương trình mục tiêu quốc gia p...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_16284\\620973280.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  eval_df = df.groupby('Answer_label').apply(lambda x: x.sample(n=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:43.122799Z",
     "start_time": "2024-09-09T08:12:43.117884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lấy các giá trị cột 'question' từ eval_df\n",
    "questions_in_eval_df = eval_df['Question'].tolist()\n",
    "\n",
    "# Lọc df để loại bỏ các hàng có giá trị cột 'question' có trong eval_df\n",
    "train_df = df[~df['Question'].isin(questions_in_eval_df)]\n",
    "\n",
    "# Hiển thị DataFrame đã lọc\n",
    "print(train_df.head())"
   ],
   "id": "7618af56a46a8a82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         title                                    Question  Answer_label  \\\n",
      "1  1719/QĐ-TTg                  Dự án 2 có mục tiêu là gì?             0   \n",
      "2  1719/QĐ-TTg                       Mục tiêu của dự án 2?             0   \n",
      "3  1719/QĐ-TTg      Đối tượng thụ hưởng của dự án 2 là ai?             1   \n",
      "5  1719/QĐ-TTg  Dự án 2 hướng tới đối tượng thụ hưởng nào?             1   \n",
      "6  1719/QĐ-TTg                 Nội dung của dự án 2 là gì?             2   \n",
      "\n",
      "                                              Answer  \n",
      "1  Mục tiêu của Dự án 2 thuộc Chương trình mục ti...  \n",
      "2  Mục tiêu của Dự án 2 thuộc Chương trình mục ti...  \n",
      "3  Đối tượng thụ hưởng của Dự án 2 thuộc Chương t...  \n",
      "5  Đối tượng thụ hưởng của Dự án 2 thuộc Chương t...  \n",
      "6  Nội dung của Dự án 2 thuộc Chương trình mục ti...  \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:43.135768Z",
     "start_time": "2024-09-09T08:12:43.132144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df1 = train_df[['Question', 'Answer']]\n",
    "eval_df1 = eval_df[['Question', 'Answer']]"
   ],
   "id": "e287ee67491e6d9f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:43.149820Z",
     "start_time": "2024-09-09T08:12:43.144786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chuyển đổi dữ liệu DataFrame thành định dạng JSON để phù hợp với Dataset.from_list\n",
    "train_data = train_df1.to_dict(orient='records')\n",
    "eval_data = eval_df1.to_dict(orient='records')"
   ],
   "id": "fd396e2ae47b93ec",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:52:04.765128Z",
     "start_time": "2024-09-10T08:52:03.782935Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "bb251fd9e01bbee",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T08:52:06.165440Z",
     "start_time": "2024-09-10T08:52:06.160958Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "41920c4315beb30d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:13:15.871864Z",
     "start_time": "2024-09-09T08:12:43.181808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "from bitsandbytes.optim import Adam8bit\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples['Question'], max_length=512, truncation=True, padding='max_length')\n",
    "    targets = tokenizer(examples['Answer'], max_length=512, truncation=True, padding='max_length')\n",
    "    inputs['labels'] = targets['input_ids']\n",
    "    return inputs\n",
    "\n",
    "# Convert DataFrame to Dataset\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "eval_dataset = Dataset.from_list(eval_data)\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_datasets = DatasetDict({\n",
    "    'train': train_dataset.map(preprocess_function, batched=True),\n",
    "    'eval': eval_dataset.map(preprocess_function, batched=True)\n",
    "})\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    output_dir='./tests',\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Use Adam8bit optimizer\n",
    "optim = Adam8bit(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Create the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['eval'],\n",
    "    optimizers=(optim, None)  # Use Adam8bit optimizer\n",
    ")\n",
    "\n",
    "# Clear cache before starting training\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ],
   "id": "850d79f328ce2bab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 3035.47 examples/s]\n",
      "Map: 100%|██████████| 426/426 [00:00<00:00, 3407.09 examples/s]\n",
      "C:\\Users\\Admin\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 57\u001B[0m\n\u001B[0;32m     54\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# Fine-tune the model\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1938\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1936\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1937\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1938\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1939\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1940\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1942\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1943\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2341\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2338\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2339\u001B[0m         grad_norm \u001B[38;5;241m=\u001B[39m _grad_norm\n\u001B[1;32m-> 2341\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2343\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_optimizer_step(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[0;32m   2345\u001B[0m optimizer_was_run \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39moptimizer_step_was_skipped\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\accelerate\\optimizer.py:172\u001B[0m, in \u001B[0;36mAcceleratedOptimizer.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerate_step_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 172\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator_state\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mXLA:\n\u001B[0;32m    174\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_state\u001B[38;5;241m.\u001B[39mis_xla_gradients_synced \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:130\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    128\u001B[0m opt \u001B[38;5;241m=\u001B[39m opt_ref()\n\u001B[0;32m    129\u001B[0m opt\u001B[38;5;241m.\u001B[39m_opt_called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[1;32m--> 130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__get__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:484\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    479\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    480\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    481\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    482\u001B[0m             )\n\u001B[1;32m--> 484\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    487\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\bitsandbytes\\optim\\optimizer.py:287\u001B[0m, in \u001B[0;36mOptimizer8bit.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    284\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_state(group, p, gindex, pindex)\n\u001B[0;32m    286\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprefetch_state(p)\n\u001B[1;32m--> 287\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    288\u001B[0m         torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39msynchronize()\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_paged:\n\u001B[0;32m    290\u001B[0m     \u001B[38;5;66;03m# all paged operation are asynchronous, we need\u001B[39;00m\n\u001B[0;32m    291\u001B[0m     \u001B[38;5;66;03m# to sync to make sure all tensors are in the right state\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\bitsandbytes\\optim\\optimizer.py:546\u001B[0m, in \u001B[0;36mOptimizer2State.update_step\u001B[1;34m(self, group, p, gindex, pindex)\u001B[0m\n\u001B[0;32m    544\u001B[0m     state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax2\u001B[39m\u001B[38;5;124m\"\u001B[39m], state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnew_max2\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnew_max2\u001B[39m\u001B[38;5;124m\"\u001B[39m], state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax2\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    545\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate1\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39muint8 \u001B[38;5;129;01mand\u001B[39;00m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock_wise\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 546\u001B[0m     \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_update_8bit_blockwise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    547\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    549\u001B[0m \u001B[43m        \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstate1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstate2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbetas\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbetas\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    555\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mqmap1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mqmap2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mabsmax1\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    560\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mabsmax2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    561\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    562\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgnorm_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgnorm_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    563\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskip_zeros\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mskip_zeros\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    564\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\bitsandbytes\\functional.py:1774\u001B[0m, in \u001B[0;36moptimizer_update_8bit_blockwise\u001B[1;34m(optimizer_name, g, p, state1, state2, beta1, beta2, eps, step, lr, qmap1, qmap2, absmax1, absmax2, weight_decay, gnorm_scale, skip_zeros)\u001B[0m\n\u001B[0;32m   1754\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimizer_update_8bit_blockwise\u001B[39m(\n\u001B[0;32m   1755\u001B[0m     optimizer_name: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   1756\u001B[0m     g: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1771\u001B[0m     skip_zeros\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1772\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1773\u001B[0m     optim_func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1774\u001B[0m     prev_device \u001B[38;5;241m=\u001B[39m \u001B[43mpre_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1775\u001B[0m     is_on_gpu([g, p, state1, state2, qmap1, qmap2, absmax1, absmax2])\n\u001B[0;32m   1776\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m g\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat32 \u001B[38;5;129;01mand\u001B[39;00m state1\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39muint8:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\bitsandbytes\\functional.py:462\u001B[0m, in \u001B[0;36mpre_call\u001B[1;34m(device)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpre_call\u001B[39m(device):\n\u001B[1;32m--> 462\u001B[0m     prev_device \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    463\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mset_device(device)\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prev_device\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:878\u001B[0m, in \u001B[0;36mcurrent_device\u001B[1;34m()\u001B[0m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcurrent_device\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m    877\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 878\u001B[0m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_getDevice()\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:305\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    300\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    303\u001B[0m     )\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    306\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    309\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:26:18.124794Z",
     "start_time": "2024-09-09T08:26:18.109865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__)          # Kiểm tra phiên bản PyTorch\n"
   ],
   "id": "85ce54694411902d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "2.4.1+cpu\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
